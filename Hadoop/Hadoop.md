# Hadoop

## 1.项目结构

##### 1.1hadoop简介

- Hadoop两大核心：分布式存储、分布式计算

##### 1.2Hadoop项目架构

- HDFS（分布式文件系统）
- YARN：资源调度
- MapReduce：离线批处理（基于磁盘）
- Spark：数据处理，逻辑向MapReduce，但是基于内存，所以性能高
- Tez：构建有向无环图
- Hive：数据仓库（用于决策分析）
- Pig：流数据处理（轻量级分析）类似SQL，轻量级编程语言
- Zookeeper：分布式协调服务
- Oozie：Hadoop上的工作流管理工具
- HBASE：分布式数据库（列族数据库），支持随机读写
- Flume：日志收集
- Sqoop：数据导入导出
- Ambari：快速部署工具

## 2.分布式文件系统HDFS：Hadoop Distributed File System

- 分为主从节点

##### 2.1HDFS实现目标

- 兼容廉价的硬件设备
- 实现流数据读写
- 支持大数据集
- 不适合低延迟数据访问，不满足实时性需求
- 无法高效存储大量小文件

##### 2.2HDFS相关概念

1. 块：分摊磁盘读写开销（寻址开销），普通计算机每块几千字节，HDFS则是64M，或128M，为什么要这么设计

   - 支持面向大规模数据存储
   - 降低分布式节点的寻址开销

   但是也有缺点

   - 如果块过大导致MapReduce就一两个任务执行完全牺牲MapReduce的并行度，发挥不了分布式并行处理的效果

##### 2.3主从节点

1. 名称节点（主）

   - FsImage，保存文件树（文件的复制等级、块大小以及组成文件的块、访问权限、修改访问时间）

   ​            Shell命令启动服务，读出FsIamge和EditLog，更新出最新元数据，然后更新FsImage，在创建一个EditLog

   

   - EditLog：

2. 第二名称节点：冷备份

   - 为了解决EditLog的不断增大，定期的与名称节点通信，让名称节点停止对EditLog的使用，名称节点会创建一个edit.new并将EditLog的信息赋值给edit.new，EditLog会被第二名称节点取走，第二名称节点吧FsImage和EditLog都拷贝过来，并合并，得到新的FsImage，再发回给名称节点，edit.new重新改名为EditLog

数据节点和名称节点实时交互完成信息的更新

##### 2.4HDFS存储原理

1. 数据冗余保存问题：底层为廉价的集群---导致不断出故障，解决办法是冗余保存数据（1.2.3.4），他带来的好处

   - 加快访问速度
   - 很容易检查错误
   - 保证数据可靠性

2. 数据保存策略问题

   - 如果数据存储冗余度为三，那么存储一个块，应该是有三个相同的副本，第一个副本放在你所上传的node节点（或者HDFS会找一个CPU不太忙的节点）
   - 第二副本会放在不同机架节点上
   - 第三副本放在第一个块相同机架不同的节点上
   - 如果还有其他块则采用随机算法

   数据读取策略：

   - 用API计算最近的一个节点ID，如果没有随机

3. 数据恢复的问题

   - 第一名称节点出错，会在第二名称节点恢复数据（1.0等一段时间才能恢复 2.0之后用热备份不存在这个问题）
   - 数据节点定期向名称节点发送心跳信息，如果一个周期没有收到心跳信息，则别标记为不可用
   - 客户端每次传数据，都会生成一个校验码，每次访问，都要计算校验码，如果不一致则进行复制，恢复

##### 2.5HDFS数据读写过程

- FileSystem：通用文件系统抽象类，他可以被DFS、HTTP、FTP一些子类实现
- Configuration：他的构造函数会加载hdfs-site.xml,core-site.xml，他会通过地址访问

## 3.Hbase分布式数据库

### 3.1Hbase简介

- 解决HDFS、MapReduce离线大数据处理，而不具有实时数据处理的功能
- 全自动扩展

### 3.2Hbase数据模型

- 每一个值都是未经解释的字符串也就是Bytes数组
- 一个行可以有多个行键和任意多个列
- 列族：支持动态扩展

